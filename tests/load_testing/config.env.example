# Milvus Load Testing Configuration
# Copy this file to config.env and customize for your environment
# Usage: source config.env && locust -f realistic_workload.py

# =============================================================================
# Milvus Connection Settings
# =============================================================================
MILVUS_HOST=localhost
MILVUS_PORT=19530
# Or use full URI (overrides host/port if set)
# MILVUS_URI=http://localhost:19530

# =============================================================================
# Collection Settings
# =============================================================================
LOAD_TEST_COLLECTION=load_test_collection
VECTOR_DIMENSION=768

# =============================================================================
# Query Distribution (must sum to 100)
# =============================================================================
# Common queries: Hot queries following Zipfian distribution (80/20 rule)
COMMON_QUERY_WEIGHT=70

# Filtered queries: Queries with metadata filters
FILTERED_QUERY_WEIGHT=20

# Rare queries: Long-tail queries with larger result sets
RARE_QUERY_WEIGHT=10

# =============================================================================
# Query Parameters
# =============================================================================
# Number of results to return for each query type
COMMON_QUERY_LIMIT=10
FILTERED_QUERY_LIMIT=10
RARE_QUERY_LIMIT=100

# Zipfian distribution parameter (higher = more skewed toward popular items)
# Typical values: 1.1 (mild skew) to 2.0 (heavy skew)
ZIPF_PARAMETER=1.5

# =============================================================================
# Performance Targets
# =============================================================================
# These values are used to validate test results
TARGET_QPS=1000
TARGET_P50_MS=30
TARGET_P95_MS=70
TARGET_P99_MS=120
TARGET_ERROR_RATE=0.001  # 0.1%

# =============================================================================
# Load Test Scenarios
# =============================================================================
# Uncomment one of the scenarios below and adjust as needed

# Scenario 1: Baseline Performance Test
# Small load to establish baseline metrics
# USERS=10
# SPAWN_RATE=2
# RUN_TIME=5m

# Scenario 2: Normal Production Load
# Simulates typical production traffic
# USERS=100
# SPAWN_RATE=10
# RUN_TIME=30m

# Scenario 3: Peak Load Test
# Simulates peak traffic (2-3x normal)
# USERS=300
# SPAWN_RATE=30
# RUN_TIME=30m

# Scenario 4: Stress Test
# Push system to limits to find breaking point
# USERS=1000
# SPAWN_RATE=50
# RUN_TIME=1h

# Scenario 5: Endurance Test
# Long-running test to detect memory leaks and degradation
# USERS=100
# SPAWN_RATE=10
# RUN_TIME=4h
